#!/usr/bin/env python
import argparse
import sys
import models
import heapq
from nbests import NBests
import numpy as np
import itertools
from collections import namedtuple
from joblib import Parallel, delayed  
import multiprocessing

parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
parser.add_argument('-i', '--input', dest='input', default='data/input', help='File containing sentences to translate (default=data/input)')
parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm', help='File containing translation model (default=data/tm)')
parser.add_argument('-s', '--stack-size', dest='s', default=1, type=int, help='Maximum stack size (default=1)')
parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int, help='Number of sentences to decode (default=no limit)')
parser.add_argument('-l', '--language-model', dest='lm', default='data/lm', help='File containing ARPA-format language model (default=data/lm)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,  help='Verbose mode (default=off)')
# new arguments
parser.add_argument('-w', '--swapping-size', dest='swap', default=0, type=int, help='Maximum swapping size (default=0)')
#
opts = parser.parse_args()
rng = np.random.RandomState(123)

tm = models.TM(opts.tm, sys.maxint)
lm = models.LM(opts.lm)
sys.stderr.write('Decoding %s...\n' % (opts.input,))
input_sents = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]

hypothesis = namedtuple('hypothesis', 'lm_state, predecessor, phrase, phrases_logprob, lm_logprob') #all_words


def extract_english_recursive(h):
    return '' if h.predecessor is None else '%s%s ' % (extract_english_recursive(h.predecessor), h.phrase.english)

def extract_english_recursive_list(h):
    return [] if h.predecessor is None else extract_english_recursive_list(h.predecessor) + [h.phrase.english]

def get_lm_score(sentence):
    lm_logprob = 0.0
    lm_state = lm.begin()
    for word in sentence:
        (lm_state, word_logprob) = lm.score(lm_state, word)
        lm_logprob += word_logprob
    lm_logprob += lm.end(lm_state)
    return lm_logprob



def translate_sentence(sentence_index):

    lm_for_sentence = {}

    f = input_sents[sentence_index]
    # The following code implements a DP monotone decoding
    # algorithm (one that doesn't permute the target phrases).
    # Hence all hypotheses in stacks[i] represent translations of
    # the first i words of the input sentence.
    # HINT: Generalize this so that stacks[i] contains translations
    # of any i words (remember to keep track of which words those
    # are, and to estimate future costs)
    initial_hypothesis = hypothesis(lm.begin(), None, None, 0.0, 0.0)
    
    stacks = [{} for _ in f] + [{}]
    stacks[0][lm.begin()] = initial_hypothesis
    current_best_at = [-np.inf for _ in stacks]

    for i, stack in enumerate(stacks[:-1]):
        # extend the top s hypotheses in the current stack
        for h in heapq.nlargest(opts.s, stack.itervalues(), key=lambda h: h.lm_logprob + h.phrases_logprob): # prune

            for j in xrange(i+1,min(len(f)+1, i+4)):
                # direct
                if f[i:j] in tm:
                    for phrase in tm[f[i:j]]:
                        phrases_logprob = h.phrases_logprob + phrase.logprob # add phrase log-probability
                        lm_logprob = h.lm_logprob
                        lm_state = h.lm_state
                        for word in phrase.english.split():
                            (lm_state, word_logprob) = lm.score(lm_state, word)
                            lm_logprob += word_logprob
                        # add language model log-probability
                        if j == len(f):
                            lm_logprob += lm.end(lm_state)
                        new_hypothesis = hypothesis(lm_state, h, phrase, phrases_logprob, lm_logprob)
                        if lm_state not in stacks[j] or stacks[j][lm_state].phrases_logprob + stacks[j][lm_state].lm_logprob < phrases_logprob + lm_logprob: # second case is recombination
                            stacks[j][lm_state] = new_hypothesis
                            current_best_at[j] = max(current_best_at[j], phrases_logprob + lm_logprob)

            for j in xrange(i+2,min(i+7,len(f)+1)):
                # swap order: A B becomes B A
                for k in xrange(i+1, min(j, i+4)):
                    if f[i:k] in tm and f[k:j] in tm:
                        for phrase1 in tm[f[i:k]]:
                            for phrase2 in tm[f[k:j]]:
                                phrases_logprob = h.phrases_logprob + phrase1.logprob + phrase2.logprob
                                if phrases_logprob < current_best_at[j]:
                                    continue
                                lm_logprob = h.lm_logprob
                                lm_state = h.lm_state
                                for word in itertools.chain(phrase2.splitted, phrase1.splitted):
                                    (lm_state, word_logprob) = lm.score(lm_state, word)
                                    lm_logprob += word_logprob
                                # add language model log-probability
                                if j == len(f):
                                    lm_logprob += lm.end(lm_state)
                                new_hypothesis = hypothesis(lm_state, h, models.phrase(phrase2.english + " " + phrase1.english, None, None), phrases_logprob, lm_logprob)
                                if lm_state not in stacks[j] or stacks[j][lm_state].phrases_logprob + stacks[j][lm_state].lm_logprob < phrases_logprob + lm_logprob: # second case is recombination
                                    stacks[j][lm_state] = new_hypothesis
                                    current_best_at[j] = max(current_best_at[j], phrases_logprob + lm_logprob)

            for j in xrange(i+3,min(i+10,len(f)+1)):
                # swap order: A B C becomes C B A (other combinations are included in previous cases)
                for k in xrange(i+1, min(j-1, i+4)): ##### WTF
                    if f[i:k] not in tm:
                        continue
                    for l in xrange(k+1, min(j, k+4)):
                        if f[k:l] in tm and f[l:j] in tm:
                            for _phrase1 in tm[f[i:k]]:
                                if h.phrases_logprob + _phrase1.logprob < current_best_at[j]:
                                    continue

                                for _phrase2 in tm[f[k:l]]:
                                    if h.phrases_logprob + _phrase1.logprob + _phrase2.logprob < current_best_at[j]:
                                        continue

                                    for _phrase3 in tm[f[l:j]]:
                                        phrases_logprob = h.phrases_logprob + _phrase1.logprob + _phrase2.logprob + _phrase3.logprob

                                        if phrases_logprob < current_best_at[j]:
                                            continue

                                        phrases = [_phrase1, _phrase2, _phrase3]
                                        for [a, b, c] in [(0, 1, 2), (0, 2, 1), (1, 0, 2), (1, 2, 0), (2, 0, 1), (2, 1, 0)]:
                                            lm_logprob = h.lm_logprob
                                            lm_state = h.lm_state
                                            should_abort = False
                                            for word in itertools.chain(phrases[a].splitted, phrases[b].splitted, phrases[c].splitted):
                                                #if (lm_state, word) in lm_for_sentence:
                                                #    (lm_state, word_logprob) = lm_for_sentence[(lm_state, word)]
                                                #else:
                                                #    (lm_state, word_logprob) = lm.score(lm_state, word)
                                                #    lm_for_sentence[(lm_state, word)] = (lm_state, word_logprob)
                                                (lm_state, word_logprob) = lm.score(lm_state, word)
                                                lm_logprob += word_logprob
                                                if phrases_logprob + lm_logprob < current_best_at[j]:
                                                    should_abort = True
                                                    break

                                            if should_abort:
                                                continue
                                            #continue
                                            # add language model log-probability
                                            if j == len(f):
                                                lm_logprob += lm.end(lm_state)
                                            new_hypothesis = hypothesis(lm_state, h, models.phrase(phrases[a].english + " " + phrases[b].english + " " + phrases[c].english, None, None), phrases_logprob, lm_logprob)
                                            if lm_state not in stacks[j] or stacks[j][lm_state].phrases_logprob + stacks[j][lm_state].lm_logprob < phrases_logprob + lm_logprob: # second case is recombination
                                                stacks[j][lm_state] = new_hypothesis
                                                current_best_at[j] = max(current_best_at[j], phrases_logprob + lm_logprob)

            for j in xrange(i+4,min(i+10,len(f)+1)):
                for k in xrange(i+1, min(j-2, i+3)):
                    if f[i:k] not in tm:
                        continue
                    for l in xrange(k+1, min(j-1, k+4)):
                        if f[k:l] not in tm:
                            continue
                        for m in xrange(l+1, min(j, l+4)):
                            if not (f[l:m] in tm and f[m:j] in tm):
                                continue
                            for _phrase1 in tm[f[i:k]]:
                                if h.phrases_logprob + _phrase1.logprob < current_best_at[j]:
                                    continue
                                for _phrase2 in tm[f[k:l]]:
                                    if h.phrases_logprob + _phrase1.logprob + _phrase2.logprob < current_best_at[j]:
                                        continue
                                    for _phrase3 in tm[f[l:m]]:
                                        if h.phrases_logprob + _phrase1.logprob + _phrase2.logprob + _phrase3.logprob < current_best_at[j]:
                                            continue

                                        for _phrase4 in tm[f[m:j]]:

                                            phrases_logprob = h.phrases_logprob + _phrase1.logprob + _phrase2.logprob + _phrase3.logprob + _phrase4.logprob
                                            if phrases_logprob < current_best_at[j]:
                                                continue

                                            phrases = [_phrase1, _phrase2, _phrase3, _phrase4]
                                            for [a, b, c, d] in [(1, 0, 3, 2),(1, 2, 3, 0),(1, 3, 0, 2),(1, 3, 2, 0),(2, 0, 3, 1),(2, 1, 3, 0),(2, 3, 0, 1),(2, 3, 1, 0),(3, 0, 1, 2),(3, 0, 2, 1),(3, 1, 0, 2),(3, 1, 2, 0),(3, 2, 0, 1),(3, 2, 1, 0)]:
                                                lm_logprob = h.lm_logprob
                                                lm_state = h.lm_state
                                                should_abort = False
                                                for word in phrases[a].splitted + phrases[b].splitted + phrases[c].splitted + phrases[d].splitted:
                                                    (lm_state, word_logprob) = lm.score(lm_state, word)
                                                    lm_logprob += word_logprob
                                                    if phrases_logprob + lm_logprob < current_best_at[j]:
                                                        should_abort = True
                                                        break
                                                if should_abort:
                                                    continue
                                                # add language model log-probability
                                                if j == len(f):
                                                    lm_logprob += lm.end(lm_state)
                                                new_hypothesis = hypothesis(lm_state, h, models.phrase(phrases[a].english + " " + phrases[b].english + " " + phrases[c].english + " " + phrases[d].english, None, None), phrases_logprob, lm_logprob)
                                                if lm_state not in stacks[j] or stacks[j][lm_state].phrases_logprob + stacks[j][lm_state].lm_logprob < phrases_logprob + lm_logprob: # second case is recombination
                                                    stacks[j][lm_state] = new_hypothesis
                                                    current_best_at[j] = max(current_best_at[j], phrases_logprob + lm_logprob)
    
    
    # find best translation by looking at the best scoring hypothesis
    # on the last stack
    possibilities = []
    for h in stacks[-1].itervalues():
        possibilities.append((h.phrases_logprob, h.lm_logprob, extract_english_recursive(h).rstrip().split(" ")))
    
    #winner = max(stacks[-1].itervalues(), key=lambda h: h.lm_logprob + h.phrases_logprob)
    #print extract_english_recursive(winner)
    
    winner = max(possibilities, key=lambda h: h[0] + h[1])
    sys.stderr.write(str(sentence_index) + " " + " ".join(winner[2]) + "\n")
    return " ".join(winner[2])
    
    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write('LM = %f, TM = %f, Total = %f\n' %
            (winner.lm_logprob + winner.phrases_logprob - tm_logprob, tm_logprob, winner.lm_logprob + winner.phrases_logprob))

num_cores = multiprocessing.cpu_count()
translated_sentences = Parallel(n_jobs=num_cores)(delayed(translate_sentence)(i) for i in range(len(input_sents)))


print "\n".join(translated_sentences)